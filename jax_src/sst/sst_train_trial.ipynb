{
 "cells": [
  {
   "cell_type": "code",
   "id": "85e5a969d1f98c1d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T18:10:46.321503Z",
     "start_time": "2024-04-11T18:10:45.571180Z"
    }
   },
   "source": [
    "import optax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import matplotlib.pyplot as plt\n",
    "import jax  # noqa: F401\n",
    "\n",
    "from jax_src.train import train, make_optimizer\n",
    "from jax_src.generator import save_net\n",
    "from jax_src.sst import (\n",
    "    sst_loss_fixed_wh,  # noqa: F401\n",
    "    eval_net,  # noqa: F401\n",
    "    load_sst_net,  # noqa: F401\n",
    "    sst_chen_consecutive,  # noqa: F401\n",
    "    wass2_errors_normal,  # noqa: F401\n",
    "    make_sst_net,  # noqa: F401\n",
    ")\n",
    "from jax_src.discriminator import marginal_wass2_error\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "dtype = jnp.float64\n",
    "\n",
    "\n",
    "def plot_losses(_losses_list):\n",
    "    all_losses = jnp.abs(jnp.concatenate(_losses_list, axis=0))\n",
    "    # Get rid of spikes\n",
    "    bound1 = jnp.min(all_losses) + 3 * jnp.std(all_losses)\n",
    "    losses_pruned = all_losses[all_losses < bound1]\n",
    "    bound2 = jnp.mean(losses_pruned) + 3 * jnp.std(losses_pruned)\n",
    "    all_losses = jnp.clip(all_losses, 0.0, bound2)\n",
    "    plt.plot(all_losses)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## The Chen-trained Neural net achieves a Wasserstein error of 3.271e-5",
   "id": "21091ce722bcda6b"
  },
  {
   "cell_type": "code",
   "id": "161b04a7cf4bcd01",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T18:11:12.696118Z",
     "start_time": "2024-04-11T18:11:09.984283Z"
    }
   },
   "source": [
    "# Either make a new net or load a pre-trained one\n",
    "noise_size = 3\n",
    "hidden_dim = 16\n",
    "num_layers = 3\n",
    "leaky_slope = 0.01\n",
    "use_multlayer = True\n",
    "# net = make_sst_net(\n",
    "#     jr.key(1),\n",
    "#     noise_size,\n",
    "#     hidden_dim,\n",
    "#     num_layers,\n",
    "#     leaky_slope,\n",
    "#     use_multlayer,\n",
    "#     dtype=dtype,\n",
    "#     use_batch_norm=False\n",
    "# )\n",
    "saving = True\n",
    "net = load_sst_net(\n",
    "    \"/home/andy/PycharmProjects/Levy_CFGAN/numpy_nets/\",\n",
    "    noise_size,\n",
    "    hidden_dim,\n",
    "    num_layers,\n",
    "    leaky_slope,\n",
    "    use_multlayer,\n",
    "    dtype,\n",
    "    use_batch_norm=False,\n",
    "    use_activation=True,\n",
    ")\n",
    "losses_list = []\n",
    "GLOBAL_KEY = jr.key(7)\n",
    "\n",
    "# net without training\n",
    "net_best, _, _ = eval_net(net, jr.key(6), 100, 2**20, -1, True, saving)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error: 0.006662, variance error: 0.0009496, avg var: 0.05002, wass error: 3.271e-05, score: 0.02005\n",
      "Inital score: 0.02005\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## The average Wasserstein error of a normal distribution with the right conditional mean and variance is 7.67e-4",
   "id": "d3d639914dbd1ba4"
  },
  {
   "cell_type": "code",
   "id": "d06d1b92e21c5a8d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T21:07:27.771553Z",
     "start_time": "2024-04-11T21:07:26.548624Z"
    }
   },
   "source": [
    "print(wass2_errors_normal(jr.key(0), True))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for w=0.4302, hh=0.4289: 0.0004312\n",
      "Error for w=-2.865, hh=-0.6711: 0.00107\n",
      "Error for w=-4.189, hh=-0.5475: 0.001146\n",
      "Error for w=-0.9949, hh=0.9425: 0.0005802\n",
      "Error for w=-0.4197, hh=0.2238: 0.0004544\n",
      "Error for w=-0.4521, hh=-0.0696: 0.000491\n",
      "Error for w=-1.14, hh=0.006232: 0.0009128\n",
      "Error for w=-1.985, hh=-0.1498: 0.001075\n",
      "Error for w=-0.3316, hh=0.3142: 0.0003915\n",
      "Error for w=-1.356, hh=-0.2088: 0.0009616\n",
      "Error for w=-1.034, hh=0.422: 0.0007774\n",
      "Error for w=-3.419, hh=0.0187: 0.001137\n",
      "Error for w=1.29, hh=1.287: 0.0006244\n",
      "Error for w=0.3729, hh=-0.5267: 0.000386\n",
      "Error for w=-0.6617, hh=-0.04992: 0.000645\n",
      "Error for w=-3.103, hh=1.266: 0.001033\n",
      "Error for w=-0.9551, hh=-0.2237: 0.0008003\n",
      "Error for w=1.119, hh=-1.58: 0.0005552\n",
      "Error for w=-1.396, hh=-0.1825: 0.0009771\n",
      "Error for w=-1.259, hh=0.6715: 0.0007793\n",
      "0.0007614567421490231\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BB loss",
   "id": "5eea272b345ec950"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Finished rep 1/100 ======== mean loss: 8.199e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001992, score: 0.09959\n",
      "\n",
      "======== Finished rep 2/100 ======== mean loss: 8.133e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.000109, score: 0.05449\n",
      "\n",
      "======== Finished rep 3/100 ======== mean loss: 8.429e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001144, score: 0.05721\n",
      "\n",
      "======== Finished rep 4/100 ======== mean loss: 8.547e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 9.377e-05, score: 0.04688\n",
      "New best net with score 0.04688\n",
      "\n",
      "======== Finished rep 5/100 ======== mean loss: 8.128e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001263, score: 0.06313\n",
      "\n",
      "======== Finished rep 6/100 ======== mean loss: 8.387e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 5.947e-05, score: 0.02973\n",
      "New best net with score 0.02973\n",
      "\n",
      "======== Finished rep 7/100 ======== mean loss: 8.33e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001215, score: 0.06074\n",
      "\n",
      "======== Finished rep 8/100 ======== mean loss: 8.238e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.000181, score: 0.09052\n",
      "\n",
      "======== Finished rep 9/100 ======== mean loss: 8.773e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 8.531e-05, score: 0.04265\n",
      "\n",
      "======== Finished rep 10/100 ======== mean loss: 8.236e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001045, score: 0.05226\n",
      "\n",
      "======== Finished rep 11/100 ======== mean loss: 8.455e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 6.179e-05, score: 0.03089\n",
      "\n",
      "======== Finished rep 12/100 ======== mean loss: 8.53e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0002213, score: 0.1107\n",
      "\n",
      "======== Finished rep 13/100 ======== mean loss: 8.052e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 9.781e-05, score: 0.04891\n",
      "\n",
      "======== Finished rep 14/100 ======== mean loss: 8.641e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 9.318e-05, score: 0.04659\n",
      "\n",
      "======== Finished rep 15/100 ======== mean loss: 8.798e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001745, score: 0.08726\n",
      "\n",
      "======== Finished rep 16/100 ======== mean loss: 8.334e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 6.554e-05, score: 0.03277\n",
      "\n",
      "======== Finished rep 17/100 ======== mean loss: 8.172e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001477, score: 0.07384\n",
      "\n",
      "======== Finished rep 18/100 ======== mean loss: 8.523e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 4.281e-05, score: 0.02141\n",
      "New best net with score 0.02141\n",
      "\n",
      "======== Finished rep 19/100 ======== mean loss: 8.119e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 5.538e-05, score: 0.02769\n",
      "\n",
      "======== Finished rep 20/100 ======== mean loss: 7.922e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0002415, score: 0.1208\n",
      "\n",
      "======== Finished rep 21/100 ======== mean loss: 8.42e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 9.943e-05, score: 0.04972\n",
      "\n",
      "======== Finished rep 22/100 ======== mean loss: 8.802e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 8.081e-05, score: 0.04041\n",
      "\n",
      "======== Finished rep 23/100 ======== mean loss: 8.372e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 6.92e-05, score: 0.0346\n",
      "\n",
      "======== Finished rep 24/100 ======== mean loss: 8.199e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 6.835e-05, score: 0.03417\n",
      "\n",
      "======== Finished rep 25/100 ======== mean loss: 8.252e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 3.271e-05, score: 0.01636\n",
      "New best net with score 0.01636\n",
      "\n",
      "======== Finished rep 26/100 ======== mean loss: 8.386e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 6.144e-05, score: 0.03072\n",
      "\n",
      "======== Finished rep 27/100 ======== mean loss: 8.386e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.000318, score: 0.159\n",
      "\n",
      "======== Finished rep 28/100 ======== mean loss: 8.201e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 7.057e-05, score: 0.03529\n",
      "\n",
      "======== Finished rep 29/100 ======== mean loss: 8.519e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 5.999e-05, score: 0.02999\n",
      "\n",
      "======== Finished rep 30/100 ======== mean loss: 8.737e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 9.606e-05, score: 0.04803\n",
      "\n",
      "======== Finished rep 31/100 ======== mean loss: 8.288e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 8.705e-05, score: 0.04352\n",
      "\n",
      "======== Finished rep 32/100 ======== mean loss: 8.606e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001276, score: 0.06379\n",
      "\n",
      "======== Finished rep 33/100 ======== mean loss: 8.077e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 7.24e-05, score: 0.0362\n",
      "\n",
      "======== Finished rep 34/100 ======== mean loss: 8.327e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001278, score: 0.06392\n",
      "\n",
      "======== Finished rep 35/100 ======== mean loss: 8.697e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 6.688e-05, score: 0.03344\n",
      "\n",
      "======== Finished rep 36/100 ======== mean loss: 8.343e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 7.957e-05, score: 0.03979\n",
      "\n",
      "======== Finished rep 37/100 ======== mean loss: 8.061e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 6.35e-05, score: 0.03175\n",
      "\n",
      "======== Finished rep 38/100 ======== mean loss: 8.263e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 9.699e-05, score: 0.0485\n",
      "\n",
      "======== Finished rep 39/100 ======== mean loss: 8.25e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001139, score: 0.05693\n",
      "\n",
      "======== Finished rep 40/100 ======== mean loss: 8.295e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 9.171e-05, score: 0.04586\n",
      "\n",
      "======== Finished rep 41/100 ======== mean loss: 8.404e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001526, score: 0.07629\n",
      "\n",
      "======== Finished rep 42/100 ======== mean loss: 8.631e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0003261, score: 0.1631\n",
      "\n",
      "======== Finished rep 43/100 ======== mean loss: 8.311e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 4.284e-05, score: 0.02142\n",
      "\n",
      "======== Finished rep 44/100 ======== mean loss: 8.29e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001007, score: 0.05037\n",
      "\n",
      "======== Finished rep 45/100 ======== mean loss: 8.559e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 6.198e-05, score: 0.03099\n",
      "\n",
      "======== Finished rep 46/100 ======== mean loss: 8.128e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0004368, score: 0.2184\n",
      "\n",
      "======== Finished rep 47/100 ======== mean loss: 8.268e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001397, score: 0.06985\n",
      "\n",
      "======== Finished rep 48/100 ======== mean loss: 8.276e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.000168, score: 0.084\n",
      "\n",
      "======== Finished rep 49/100 ======== mean loss: 8.336e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001206, score: 0.0603\n",
      "\n",
      "======== Finished rep 50/100 ======== mean loss: 8.031e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 7.22e-05, score: 0.0361\n",
      "\n",
      "======== Finished rep 51/100 ======== mean loss: 8.287e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001686, score: 0.08431\n",
      "\n",
      "======== Finished rep 52/100 ======== mean loss: 8.327e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 7.444e-05, score: 0.03722\n",
      "\n",
      "======== Finished rep 53/100 ======== mean loss: 8.529e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 9.682e-05, score: 0.04841\n",
      "\n",
      "======== Finished rep 54/100 ======== mean loss: 8.277e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001093, score: 0.05467\n",
      "\n",
      "======== Finished rep 55/100 ======== mean loss: 8.279e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 9.05e-05, score: 0.04525\n",
      "\n",
      "======== Finished rep 56/100 ======== mean loss: 8.099e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001352, score: 0.06758\n",
      "\n",
      "======== Finished rep 57/100 ======== mean loss: 8.369e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 9.098e-05, score: 0.04549\n",
      "\n",
      "======== Finished rep 58/100 ======== mean loss: 8.321e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001197, score: 0.05985\n",
      "\n",
      "======== Finished rep 59/100 ======== mean loss: 8.4e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 7.263e-05, score: 0.03631\n",
      "\n",
      "======== Finished rep 60/100 ======== mean loss: 8e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001427, score: 0.07133\n",
      "\n",
      "======== Finished rep 61/100 ======== mean loss: 8.446e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0002263, score: 0.1132\n",
      "\n",
      "======== Finished rep 62/100 ======== mean loss: 7.932e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 7.69e-05, score: 0.03845\n",
      "\n",
      "======== Finished rep 63/100 ======== mean loss: 8.203e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0002011, score: 0.1005\n",
      "\n",
      "======== Finished rep 64/100 ======== mean loss: 8.098e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001475, score: 0.07375\n",
      "\n",
      "======== Finished rep 65/100 ======== mean loss: 7.913e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001066, score: 0.05331\n",
      "\n",
      "======== Finished rep 66/100 ======== mean loss: 8.38e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0003831, score: 0.1916\n",
      "\n",
      "======== Finished rep 67/100 ======== mean loss: 7.987e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0002694, score: 0.1347\n",
      "\n",
      "======== Finished rep 68/100 ======== mean loss: 8.024e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0002221, score: 0.1111\n",
      "\n",
      "======== Finished rep 69/100 ======== mean loss: 8.323e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001104, score: 0.05518\n",
      "\n",
      "======== Finished rep 70/100 ======== mean loss: 8.522e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 8.194e-05, score: 0.04097\n",
      "\n",
      "======== Finished rep 71/100 ======== mean loss: 8.412e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001214, score: 0.06072\n",
      "\n",
      "======== Finished rep 72/100 ======== mean loss: 7.985e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0003137, score: 0.1568\n",
      "\n",
      "======== Finished rep 73/100 ======== mean loss: 8.224e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0002025, score: 0.1012\n",
      "\n",
      "======== Finished rep 74/100 ======== mean loss: 8.137e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0005218, score: 0.2609\n",
      "\n",
      "======== Finished rep 75/100 ======== mean loss: 8.102e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0001201, score: 0.06006\n",
      "\n",
      "======== Finished rep 76/100 ======== mean loss: 8.461e-06\n",
      "Mean error: 0.0, variance error: 0.0, avg var: 0.0, wass error: 0.0002091, score: 0.1046\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_reps):\n\u001B[1;32m      9\u001B[0m     GLOBAL_KEY, temp_key \u001B[38;5;241m=\u001B[39m jr\u001B[38;5;241m.\u001B[39msplit(GLOBAL_KEY, \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m     net, discr, opt_state, losses \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtemp_key\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m        \u001B[49m\u001B[43mopt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m        \u001B[49m\u001B[43mopt_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m        \u001B[49m\u001B[43msst_loss_fixed_wh\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m1.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m     avg_loss \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39mmean(jnp\u001B[38;5;241m.\u001B[39mabs(losses))\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m======== Finished rep \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_reps\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ======== mean loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mavg_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/LevyGAN/levygan_venv/lib/python3.11/site-packages/jax/_src/pjit.py:248\u001B[0m, in \u001B[0;36m_cpp_pjit.<locals>.cache_miss\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;129m@api_boundary\u001B[39m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcache_miss\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 248\u001B[0m   outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked \u001B[38;5;241m=\u001B[39m \u001B[43m_python_pjit_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[43m      \u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minfer_params_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    250\u001B[0m   executable \u001B[38;5;241m=\u001B[39m _read_most_recent_pjit_call_executable(jaxpr)\n\u001B[1;32m    251\u001B[0m   maybe_fastpath_data \u001B[38;5;241m=\u001B[39m _get_fastpath_data(\n\u001B[1;32m    252\u001B[0m       executable, out_tree, args_flat, out_flat, attrs_tracked)\n",
      "File \u001B[0;32m~/PycharmProjects/LevyGAN/levygan_venv/lib/python3.11/site-packages/jax/_src/pjit.py:143\u001B[0m, in \u001B[0;36m_python_pjit_helper\u001B[0;34m(fun, infer_params_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    141\u001B[0m   args_flat \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m*\u001B[39minit_states, \u001B[38;5;241m*\u001B[39margs_flat]\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 143\u001B[0m   out_flat \u001B[38;5;241m=\u001B[39m \u001B[43mpjit_p\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbind\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs_flat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m pxla\u001B[38;5;241m.\u001B[39mDeviceAssignmentMismatchError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    145\u001B[0m   fails, \u001B[38;5;241m=\u001B[39m e\u001B[38;5;241m.\u001B[39margs\n",
      "File \u001B[0;32m~/PycharmProjects/LevyGAN/levygan_venv/lib/python3.11/site-packages/jax/_src/core.py:2727\u001B[0m, in \u001B[0;36mAxisPrimitive.bind\u001B[0;34m(self, *args, **params)\u001B[0m\n\u001B[1;32m   2723\u001B[0m axis_main \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m((axis_frame(a)\u001B[38;5;241m.\u001B[39mmain_trace \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m used_axis_names(\u001B[38;5;28mself\u001B[39m, params)),\n\u001B[1;32m   2724\u001B[0m                 default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m t: \u001B[38;5;28mgetattr\u001B[39m(t, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlevel\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m   2725\u001B[0m top_trace \u001B[38;5;241m=\u001B[39m (top_trace \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m axis_main \u001B[38;5;129;01mor\u001B[39;00m axis_main\u001B[38;5;241m.\u001B[39mlevel \u001B[38;5;241m<\u001B[39m top_trace\u001B[38;5;241m.\u001B[39mlevel\n\u001B[1;32m   2726\u001B[0m              \u001B[38;5;28;01melse\u001B[39;00m axis_main\u001B[38;5;241m.\u001B[39mwith_cur_sublevel())\n\u001B[0;32m-> 2727\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbind_with_trace\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtop_trace\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/LevyGAN/levygan_venv/lib/python3.11/site-packages/jax/_src/core.py:423\u001B[0m, in \u001B[0;36mPrimitive.bind_with_trace\u001B[0;34m(self, trace, args, params)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbind_with_trace\u001B[39m(\u001B[38;5;28mself\u001B[39m, trace, args, params):\n\u001B[0;32m--> 423\u001B[0m   out \u001B[38;5;241m=\u001B[39m \u001B[43mtrace\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_primitive\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrace\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfull_raise\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    424\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmap\u001B[39m(full_lower, out) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmultiple_results \u001B[38;5;28;01melse\u001B[39;00m full_lower(out)\n",
      "File \u001B[0;32m~/PycharmProjects/LevyGAN/levygan_venv/lib/python3.11/site-packages/jax/_src/core.py:913\u001B[0m, in \u001B[0;36mEvalTrace.process_primitive\u001B[0;34m(self, primitive, tracers, params)\u001B[0m\n\u001B[1;32m    912\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprocess_primitive\u001B[39m(\u001B[38;5;28mself\u001B[39m, primitive, tracers, params):\n\u001B[0;32m--> 913\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mprimitive\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimpl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtracers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/LevyGAN/levygan_venv/lib/python3.11/site-packages/jax/_src/pjit.py:1409\u001B[0m, in \u001B[0;36m_pjit_call_impl\u001B[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001B[0m\n\u001B[1;32m   1406\u001B[0m has_explicit_sharding \u001B[38;5;241m=\u001B[39m _pjit_explicit_sharding(\n\u001B[1;32m   1407\u001B[0m     in_shardings, out_shardings, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m   1408\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m xla_extension_version \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m226\u001B[39m:\n\u001B[0;32m-> 1409\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mxc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_xla\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpjit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1410\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcall_impl_cache_miss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdonated_argnums\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1411\u001B[0m \u001B[43m      \u001B[49m\u001B[43mtree_util\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_registry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1412\u001B[0m \u001B[43m      \u001B[49m\u001B[43mpxla\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshard_arg\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mxla_extension_version\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m229\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpxla\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtemp_shard_arg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[1;32m   1413\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_get_cpp_global_cache\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhas_explicit_sharding\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1414\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1415\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m xc\u001B[38;5;241m.\u001B[39m_xla\u001B[38;5;241m.\u001B[39mpjit(name, f, call_impl_cache_miss, [], [], donated_argnums,  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   1416\u001B[0m                       tree_util\u001B[38;5;241m.\u001B[39mdispatch_registry,\n\u001B[1;32m   1417\u001B[0m                       _get_cpp_global_cache(has_explicit_sharding))(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[0;32m~/PycharmProjects/LevyGAN/levygan_venv/lib/python3.11/site-packages/jax/_src/pjit.py:1392\u001B[0m, in \u001B[0;36m_pjit_call_impl.<locals>.call_impl_cache_miss\u001B[0;34m(*args_, **kwargs_)\u001B[0m\n\u001B[1;32m   1391\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_impl_cache_miss\u001B[39m(\u001B[38;5;241m*\u001B[39margs_, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs_):\n\u001B[0;32m-> 1392\u001B[0m   out_flat, compiled \u001B[38;5;241m=\u001B[39m \u001B[43m_pjit_call_impl_python\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1393\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjaxpr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjaxpr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43min_shardings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43min_shardings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1394\u001B[0m \u001B[43m      \u001B[49m\u001B[43mout_shardings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout_shardings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresource_env\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresource_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1395\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdonated_invars\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdonated_invars\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_unused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_unused\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1396\u001B[0m \u001B[43m      \u001B[49m\u001B[43minline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minline\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1397\u001B[0m   fastpath_data \u001B[38;5;241m=\u001B[39m _get_fastpath_data(\n\u001B[1;32m   1398\u001B[0m       compiled, tree_structure(out_flat), args, out_flat, [])\n\u001B[1;32m   1399\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m out_flat, fastpath_data\n",
      "File \u001B[0;32m~/PycharmProjects/LevyGAN/levygan_venv/lib/python3.11/site-packages/jax/_src/pjit.py:1348\u001B[0m, in \u001B[0;36m_pjit_call_impl_python\u001B[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001B[0m\n\u001B[1;32m   1342\u001B[0m   distributed_debug_log((\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRunning pjit\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124md function\u001B[39m\u001B[38;5;124m\"\u001B[39m, name),\n\u001B[1;32m   1343\u001B[0m                         (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124min_shardings\u001B[39m\u001B[38;5;124m\"\u001B[39m, in_shardings),\n\u001B[1;32m   1344\u001B[0m                         (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mout_shardings\u001B[39m\u001B[38;5;124m\"\u001B[39m, out_shardings),\n\u001B[1;32m   1345\u001B[0m                         (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mabstract args\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mmap\u001B[39m(xla\u001B[38;5;241m.\u001B[39mabstractify, args)),\n\u001B[1;32m   1346\u001B[0m                         (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfingerprint\u001B[39m\u001B[38;5;124m\"\u001B[39m, fingerprint))\n\u001B[1;32m   1347\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1348\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcompiled\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsafe_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m, compiled\n\u001B[1;32m   1349\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFloatingPointError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1350\u001B[0m   \u001B[38;5;28;01massert\u001B[39;00m config\u001B[38;5;241m.\u001B[39mdebug_nans\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;129;01mor\u001B[39;00m config\u001B[38;5;241m.\u001B[39mdebug_infs\u001B[38;5;241m.\u001B[39mvalue  \u001B[38;5;66;03m# compiled_fun can only raise in this case\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/LevyGAN/levygan_venv/lib/python3.11/site-packages/jax/_src/profiler.py:336\u001B[0m, in \u001B[0;36mannotate_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m    334\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    335\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m TraceAnnotation(name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdecorator_kwargs):\n\u001B[0;32m--> 336\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    337\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m wrapper\n",
      "File \u001B[0;32m~/PycharmProjects/LevyGAN/levygan_venv/lib/python3.11/site-packages/jax/_src/interpreters/pxla.py:1201\u001B[0m, in \u001B[0;36mExecuteReplicated.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1198\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mordered_effects \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhas_unordered_effects\n\u001B[1;32m   1199\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhas_host_callbacks):\n\u001B[1;32m   1200\u001B[0m   input_bufs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_add_tokens_to_inputs(input_bufs)\n\u001B[0;32m-> 1201\u001B[0m   results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mxla_executable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute_sharded\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1202\u001B[0m \u001B[43m      \u001B[49m\u001B[43minput_bufs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwith_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m   1203\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1204\u001B[0m   result_token_bufs \u001B[38;5;241m=\u001B[39m results\u001B[38;5;241m.\u001B[39mdisassemble_prefix_into_single_device_arrays(\n\u001B[1;32m   1205\u001B[0m       \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mordered_effects))\n\u001B[1;32m   1206\u001B[0m   sharded_runtime_token \u001B[38;5;241m=\u001B[39m results\u001B[38;5;241m.\u001B[39mconsume_token()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 3,
   "source": [
    "num_reps = 100\n",
    "num_steps = 2**13\n",
    "# Set the learning rate schedule\n",
    "# schedule = optax.cosine_decay_schedule(1e-3, num_steps * num_reps, 1e-4)\n",
    "schedule = optax.constant_schedule(2e-4)\n",
    "opt, opt_state = make_optimizer(net, None, schedule, beta1=0.95, beta2=0.995)\n",
    "\n",
    "for i in range(num_reps):\n",
    "    GLOBAL_KEY, temp_key = jr.split(GLOBAL_KEY, 2)\n",
    "    net, discr, opt_state, losses = train(\n",
    "        net,\n",
    "        None,\n",
    "        temp_key,\n",
    "        num_steps,\n",
    "        opt,\n",
    "        opt_state,\n",
    "        sst_loss_fixed_wh,\n",
    "        1.0,\n",
    "        1,\n",
    "    )\n",
    "    avg_loss = jnp.mean(jnp.abs(losses))\n",
    "    print(f\"======== Finished rep {i+1}/{num_reps} ======== mean loss: {avg_loss:.4}\")\n",
    "    net_best, _, _ = eval_net(net, jr.key(6), 0, 2**20, net_best, True, saving)\n",
    "    # plot_losses(losses_list)\n",
    "    print(\"\\n\")"
   ],
   "id": "c837a40f57441bbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 6,
   "source": "save_net(net, \"/home/andy/PycharmProjects/Levy_CFGAN/numpy_nets/sst_\")",
   "id": "3e9b772e0d8dd064"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check the SST Chen's relation is correct",
   "id": "40cd150bad746c84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 2^22.0, wass dist: 0.5846481323242188\n",
      "num samples: 2^21.0, wass dist: 0.072193, mean: 0.2506, var: 0.2814\n",
      "num samples: 2^20.0, wass dist: 0.016293, mean: 0.3757, var: 0.3622\n",
      "num samples: 2^19.0, wass dist: 0.0045235, mean: 0.4382, var: 0.3652\n",
      "num samples: 2^18.0, wass dist: 0.0012815, mean: 0.4692, var: 0.3554\n",
      "num samples: 2^17.0, wass dist: 0.00043373, mean: 0.4852, var: 0.3489\n",
      "num samples: 2^16.0, wass dist: 0.00012418, mean: 0.494, var: 0.3433\n",
      "num samples: 2^15.0, wass dist: 0.0001847, mean: 0.4974, var: 0.3314\n",
      "num samples: 2^14.0, wass dist: 0.00036022, mean: 0.4971, var: 0.3255\n",
      "num samples: 2^13.0, wass dist: 0.00075478, mean: 0.4918, var: 0.3181\n",
      "num samples: 2^12.0, wass dist: 0.0018489, mean: 0.4901, var: 0.3049\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": [
    "import math\n",
    "\n",
    "c = jnp.zeros((2**22,), dtype=dtype)\n",
    "w = jr.normal(jr.PRNGKey(0), (2**22,), dtype=dtype)\n",
    "hh = math.sqrt(1 / 12) * jr.normal(jr.PRNGKey(0), (2**22,), dtype=dtype)\n",
    "with open(\"sst_saved_values/uncond/sst_unconditional.npy\", \"rb\") as f:\n",
    "    c_true = jnp.load(f)[: 2**20]\n",
    "\n",
    "wass_dist = marginal_wass2_error(c, c_true)\n",
    "print(f\"num samples: 2^{math.log2(c.shape[0])}, wass dist: {wass_dist}\")\n",
    "\n",
    "for i in range(10):\n",
    "    w, hh, c = sst_chen_consecutive(w, hh, c)\n",
    "\n",
    "    wass_dist = marginal_wass2_error(c, c_true)\n",
    "    print(\n",
    "        f\"num samples: 2^{math.log2(c.shape[0])}, wass dist: {wass_dist:.5}, mean: {jnp.mean(c):.4}, var: {jnp.var(c):.4}\"\n",
    "    )"
   ],
   "id": "4f8d5b1e6256dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
